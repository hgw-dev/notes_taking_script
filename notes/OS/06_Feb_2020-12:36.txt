
    ## Thursday February 06, 2020 ##
    
why threads?
	concurrency - different things happening at once
	parallelism - do same thing with more resources
		- ex. mult processors to speed-up simulation

alternate threading models
	kernel threads
	OS scheduler deals directly with threads

	alt idea: library code handles threads
		kernel doesn't know about threads w/in process 
		hierarchy of schedulers - one for processes, one within each process
		not currently common - awkward with multicore

thread versus process state
	thread state - kept in `thread control block`
		registers (including stack pointer, program counter)
		scheduling state (runnable, waiting, etc)
		other info

	process state - kept in `process control block`

linux idea:
	task_struct
	linux model: single "task" structure = thread
		pointers to address space, open file list, etc
		pointers can be shared
		fork()-like system call "clone": choose what to share
			open files, address space, everything
			specify new stack pointer 

	advantage:
		no special logic for threads (mostly)
			two threads in same process = tasks sharing everything possible

	posix api uses pthread_create()

pthread_create()
	args
		thread identifier
		function to run
			thread starts here, terminates if function returns
		two NULL vals
			thread attr (extra settings)
			function args

	the main() thread is special
		returning from main **exists entire process** (all its threads)
		race between main function and new thread

		so we need equiv of wait_pid()
			pthread_join() 
				takes the thread pointer
				pointer to the return value (can be NULL)

thread_sum memory layout
	each thread gets own 
		stack
		stack pointer
		program counter
		registers

thread resources
	all threads have
		new stack 
			how big? - enough most of the time
		thread control block 

	deallocated when
		can deallocate stack when thread exits
		but need to allow collecting return value
			same problem as for processes and waitpid

pthread_detach()
	marks a thread as "get rid of it when it finishes"
	don't care about return value

attribute functions can be used to allocate stack sizes and detach threads

the correctness problem
	schedulers introduce non-determinism
		scheduler might run threads in any order 
		and can switch threads at any time
	worse with threads on multicore
		cores not precisely synchronized (stalling for caches, etc)
		diff cores happen in diff order each time
	allows for "race condition" bugs
		outcome depends on whether one thread can 'race' ahead of another

atomic operation
	operation that runs to completion or not at all
	we will use these to let threads work together
	most machines: loading/storing words is atomic
	some instructions are not atomic
	ex.
		add constant to memory location
			multiple steps so other core can observe in-between result
		loading/ storing across cache blocks

	so what is atomic?
		in general, processor designer will tell you

mutual exclusion = ensuring only one thread does a particular thing at a time
critical section = code exactly one thread can execute at a time
lock = object only one thread can hold at a time

locks - an object with 
	lock/acquire - wait until lock is free, then grab it
	unlock/release - let others use lock, wakeup waiters

pthread mutex uses init, lock, and unlock